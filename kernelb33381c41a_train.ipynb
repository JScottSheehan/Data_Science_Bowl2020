{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "train_labels = pd.read_csv('data/train_labels.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "specs = pd.read_csv('data/specs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7734558, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train-specific cleaning steps\n",
    "assessed_ids = train[train['type'] == 'Assessment']['installation_id'].unique()\n",
    "train = train[train['installation_id'].isin(assessed_ids)]\n",
    "train.shape\n",
    "\n",
    "labeled_ids = train_labels['installation_id'].unique()\n",
    "train = train[train['installation_id'].isin(labeled_ids)]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "train.sort_values(['installation_id', 'timestamp'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-specific stuff\n",
    "train = pd.merge(train, train_labels, on=['installation_id', 'game_session'], how='left')\n",
    "\n",
    "train_cuts = train[(train['event_code'] == 2000) & \n",
    "                   (train['type'] == 'Assessment') & \n",
    "                   (train['accuracy_group'].notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prev_assessment_accuracy(df):\n",
    "    try:\n",
    "        acc = df[df['type'] == 'Assessment'].tail(1)['accuracy'].item()\n",
    "    except:\n",
    "        acc = np.nan\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_events_during_school_hours(df):\n",
    "    start_time = datetime(2019, 9, 5, 7, 45).time()\n",
    "    end_time = datetime(2019, 9, 6, 15, 30).time()\n",
    "    df.index = df['timestamp']\n",
    "    df = df.between_time(start_time, end_time)\n",
    "    return len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_number_of_misses(df):\n",
    "    total_number_of_misses = (df['num_correct'] == 0).sum()\n",
    "    return total_number_of_misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_of_misses(df):\n",
    "    percentage_misses = total_number_of_misses(df) / df['num_correct'].notnull()\n",
    "    return percentage_misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_exit_type_other_than_gamecompleted(df):\n",
    "    \"\"\"1 if never had an exit_type other than 'game_completed', and 0 otherwise\"\"\"\n",
    "    a = df['event_data'].apply(json.loads).apply(lambda d: d['exit_type'] if 'exit_type' in d else np.nan)\n",
    "    a = a[a.notnull()]\n",
    "    if len(a) == 0:\n",
    "        return 0\n",
    "    if (a == 'game_completed').all():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_events_correct_json(df):\n",
    "    \"\"\"Count number of events that say 'correct':true\"\"\"\n",
    "    a = df['event_data'].apply(json.loads).apply(lambda d: int(d['correct']) if 'correct' in d else np.nan)\n",
    "    a = a[a.notnull()]\n",
    "    if len(a) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_events_incorrect_json(df):\n",
    "    \"\"\"Count number of events that say 'correct':false\"\"\"\n",
    "    a = df['event_data'].apply(json.loads).apply(lambda d: int(not d['correct']) if 'correct' in d else np.nan)\n",
    "    a = a[a.notnull()]\n",
    "    if len(a) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_game_play_total_time(df):\n",
    "    session_times = df.groupby('game_session')['timestamp']\n",
    "    return (session_times.max() - session_times.min()).sum().total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_wild_click_sessions(df, clicks, seconds):\n",
    "    \"\"\"A wild click session is defined as a spurt of at least n clicks in m seconds.\n",
    "    Warning: this will measure long click sessions as multiple shorter ones.\n",
    "    \n",
    "    ARGS: \n",
    "    df -- (DataFrame) the user's complete history\n",
    "    clicks -- (int) number of clicks in the clickspurt.\n",
    "    seconds -- (float) number of seconds that define the span of a clickspurt.\n",
    "    \n",
    "    RETURNS: the amount of individual wild click sessions in player history\n",
    "    \"\"\"\n",
    "    return (df['timestamp'].diff(clicks) < timedelta(seconds=seconds)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_wild_click_session(df, clicks, seconds):\n",
    "    \"\"\"A wild click session (WCS) is defined as a spurt of at least n clicks in m seconds.\n",
    "    If you consider consecutive WCSs as a single, longer WCS, you can measure the duration of them.\n",
    "    This function returns the duration of the longest WCS in a user's history,\n",
    "    and the number of WCSs the user had if you treatconsecutive WCSs as a single, longer WCS.\n",
    "    \n",
    "    ARGS: \n",
    "    df -- (DataFrame) the user's complete history\n",
    "    clicks -- (int) number of clicks in the clickspurt.\n",
    "    seconds -- (float) number of seconds that define the span of a clickspurt.\n",
    "    \n",
    "    RETURNS: \n",
    "    longest_run -- (int) longest run of consecutive WCSs\n",
    "    number_of_runs -- (int) number of WCSs if you treat consecutive ones as a single WCS\n",
    "    \"\"\"\n",
    "    df = df.reset_index(drop=True)  # just in case there are two rows with the same index label\n",
    "    wcs_rows = (df['timestamp'].diff(clicks) < timedelta(seconds=seconds))\n",
    "    wcs_rows = wcs_rows[wcs_rows].index  # get all the locations where a single WCS occurred\n",
    "    wcs_locations = pd.Series(df.loc[wcs_rows,:].index)\n",
    "    location_diffs = wcs_locations.diff(1).iloc[1:]  # the first value is null\n",
    "\n",
    "    longest_run, number_of_runs, current_run = 0, 0, 0\n",
    "    for val in location_diffs:\n",
    "        if val == 1:\n",
    "            current_run += 1\n",
    "        else:\n",
    "            longest_run = max(longest_run, current_run)\n",
    "            if current_run > 0:\n",
    "                number_of_runs += 1\n",
    "            current_run = 0\n",
    "\n",
    "    return longest_run, number_of_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_of_current_play_session(df, break_minutes=30):\n",
    "    \"\"\"A play session is active until there are no events for at least m minutes.\"\"\"\n",
    "    df = df.reset_index(drop=True)\n",
    "    break_start_locations = (df['timestamp'].diff(1) > timedelta(minutes=break_minutes)).reset_index(drop=True)\n",
    "    break_start_locations.iloc[0] = True\n",
    "    break_start_locations = break_start_locations[break_start_locations].index\n",
    "    break_end_locations = pd.Series(break_start_locations - 1).iloc[1:]\n",
    "    break_end_locations = break_end_locations.append(pd.Series([len(df) - 1])).reset_index(drop=True)\n",
    "    session_durations = df.loc[break_end_locations, 'timestamp'].reset_index(drop=True) - df.loc[break_start_locations, 'timestamp'].reset_index(drop=True)\n",
    "    return session_durations.iloc[-1].total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_play_sessions(df, break_minutes=30):\n",
    "    \"\"\"A play session is active until there are no events for at least m minutes.\"\"\"\n",
    "    df = df.reset_index(drop=True)\n",
    "    break_start_locations = (df['timestamp'].diff(1) > timedelta(minutes=break_minutes)).reset_index(drop=True)\n",
    "    break_start_locations.iloc[0] = True\n",
    "    break_start_locations = break_start_locations[break_start_locations].index\n",
    "    break_end_locations = pd.Series(break_start_locations - 1).iloc[1:]\n",
    "    break_end_locations = break_end_locations.append(pd.Series([len(df) - 1])).reset_index(drop=True)\n",
    "    session_durations = df.loc[break_end_locations, 'timestamp'].reset_index(drop=True) - df.loc[break_start_locations, 'timestamp'].reset_index(drop=True)\n",
    "    return len(session_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_play_session_compared_to_mean(df, break_minutes=30):\n",
    "    df = df.reset_index(drop=True)\n",
    "    break_start_locations = (df['timestamp'].diff(1) > timedelta(minutes=break_minutes)).reset_index(drop=True)\n",
    "    break_start_locations.iloc[0] = True\n",
    "    break_start_locations = break_start_locations[break_start_locations].index\n",
    "    break_end_locations = pd.Series(break_start_locations - 1).iloc[1:]\n",
    "    break_end_locations = break_end_locations.append(pd.Series([len(df) - 1])).reset_index(drop=True)\n",
    "    session_durations = df.loc[break_end_locations, 'timestamp'].reset_index(drop=True) - df.loc[break_start_locations, 'timestamp'].reset_index(drop=True)\n",
    "    mean_session_duration = session_durations.mean()\n",
    "    return (mean_session_duration.total_seconds() - session_durations.iloc[-1].total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_play_session_compared_to_median(df, break_minutes=30):\n",
    "    df = df.reset_index(drop=True)\n",
    "    break_start_locations = (df['timestamp'].diff(1) > timedelta(minutes=break_minutes)).reset_index(drop=True)\n",
    "    break_start_locations.iloc[0] = True\n",
    "    break_start_locations = break_start_locations[break_start_locations].index\n",
    "    break_end_locations = pd.Series(break_start_locations - 1).iloc[1:]\n",
    "    break_end_locations = break_end_locations.append(pd.Series([len(df) - 1])).reset_index(drop=True)\n",
    "    session_durations = df.loc[break_end_locations, 'timestamp'].reset_index(drop=True) - df.loc[break_start_locations, 'timestamp'].reset_index(drop=True)\n",
    "    mean_session_duration = session_durations.median()\n",
    "    return (mean_session_duration.total_seconds() - session_durations.iloc[-1].total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_global_session_lengths(df):\n",
    "    global_session_lengths = df.groupby(['installation_id', 'game_session'])[['title_x', 'game_time', 'event_count']].max()\n",
    "    global_session_lengths[global_session_lengths['game_time'] > 0]\n",
    "    global_session_lengths = global_session_lengths.groupby('title_x')[['game_time', 'event_count']]\n",
    "    global_mean_session_lengths = global_session_lengths.mean()\n",
    "    global_median_session_lengths = global_session_lengths.median()\n",
    "    return global_mean_session_lengths, global_median_session_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_player_vs_global_features(df, global_mean_session_lengths, global_median_session_lengths):\n",
    "    session_lengths = df.groupby('game_session')[['title_x', 'game_time', 'event_count']].max()\n",
    "    session_lengths = session_lengths[session_lengths['game_time'] > 0]  # ignore sessions w/ no duration\n",
    "    player_session_lengths = session_lengths.groupby('title_x')[['game_time', 'event_count']]\n",
    "    player_mean_session_lengths = player_session_lengths.mean()\n",
    "    player_median_session_lengths = player_session_lengths.median()\n",
    "    \n",
    "    player_vs_global_mean = pd.merge(player_mean_session_lengths, global_mean_session_lengths, \n",
    "                                on='title_x', how='inner', suffixes=['_player', '_global'])\n",
    "    p_v_g_game_time_mean = player_vs_global_mean['game_time_player'] - player_vs_global_mean['game_time_global']\n",
    "    p_v_g_event_count_mean = player_vs_global_mean['event_count_player'] - player_vs_global_mean['event_count_global']\n",
    "    p_v_g_gt_sum_mean = p_v_g_game_time_mean.sum()\n",
    "    p_v_g_ec_sum_mean = p_v_g_event_count_mean.sum()\n",
    "    \n",
    "    player_vs_global_median = pd.merge(player_median_session_lengths, global_median_session_lengths, \n",
    "                                on='title_x', how='inner', suffixes=['_player', '_global'])\n",
    "    p_v_g_game_time_median = player_vs_global_median['game_time_player'] - player_vs_global_median['game_time_global']\n",
    "    p_v_g_event_count_median = player_vs_global_median['event_count_player'] - player_vs_global_median['event_count_global']\n",
    "    p_v_g_gt_sum_median = p_v_g_game_time_median.sum()\n",
    "    p_v_g_ec_sum_median = p_v_g_event_count_median.sum()\n",
    "    return (p_v_g_gt_sum_mean, p_v_g_ec_sum_mean, \n",
    "            p_v_g_gt_sum_median, p_v_g_ec_sum_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def events_from_specs():\n",
    "    df = specs\n",
    "    correct_events = df[(df['info'].str.contains('\\(Correct\\)', case=False, na=False)) | (df['info'].str.contains(' correct', case=False, na=False))]\n",
    "    correct_events = set(correct_events['event_id'])\n",
    "    incorrect_events = df[(df['info'].str.contains('\\(Inorrect\\)', case=False, na=False)) | (df['info'].str.contains('incorrect', case=False, na=False))]\n",
    "    incorrect_events = set(incorrect_events['event_id'])\n",
    "    return correct_events, incorrect_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_events_correct_eventid(df, correct_events):\n",
    "    return df['event_id'].isin(correct_events).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_events_incorrect_eventid(df, incorrect_events):\n",
    "    return df['event_id'].isin(incorrect_events).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def times_took_assess(df):\n",
    "    df_1 = df.groupby([\"installation_id\", \"title_x\"]).transform('count')\n",
    "    df_2= df_1[[\"event_id\"]]\n",
    "    df_2 = df_2.rename(columns={\"event_id\": \"times_played\"})\n",
    "    df = df.merge(df_2, left_index=True, right_index=True)\n",
    "    return df[\"times_played\"].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# added global calculations, used to create features\n",
    "global_mean_session_lengths, global_median_session_lengths = calc_global_session_lengths(pd.concat([train, test]))\n",
    "correct_events, incorrect_events = events_from_specs()\n",
    "\n",
    "a = train[[\"installation_id\", \"event_code\"]]\n",
    "a1 = a.pivot_table(index='installation_id', columns='event_code', aggfunc=len, fill_value=0)\n",
    "a1 = a1[[2010, 2020,2025, 2030, 2035,3010, 3020, 3021,3110, 3120, 3121,4020, 4025, 4030,4035, 4040, 4070,4080, 4090,4100,4110]]\n",
    "a1[\"installation_id\"] = a1.index\n",
    "a1.reset_index(drop=True, inplace=True)\n",
    "train = pd.merge(train, a1, on=['installation_id'], how='left')\n",
    "\n",
    "train[\"time_of_day\"] = train[\"timestamp\"].astype(str).str[11:13]\n",
    "train[\"time_of_day\"] = train[\"time_of_day\"].astype(int)\n",
    "train[\"segment_of_day\"] = np.where(train[\"time_of_day\"]<7, 1.524239, \n",
    "                          np.where(train[\"time_of_day\"]<12, 1.746823, \n",
    "                           np.where(train[\"time_of_day\"]<18, 1.556186, 1.502395)))\n",
    "\n",
    "train[\"assessment\"] = np.where(train[\"title_x\"]==\"Bird Measurer (Assessment)\", 1.14, \n",
    "                      np.where(train[\"title_x\"]==\"Cart Balancer (Assessment)\", 1.86, \n",
    "                       np.where(train[\"title_x\"]==\"Cauldron Filler (Assessment)\", 2.08, \n",
    "                        np.where(train[\"title_x\"]==\"Chest Sorter (Assessment)\", 0.67, \n",
    "                         np.where(train[\"title_x\"]==\"Bird Measurer (Assessment)\", 1.97, float(\"nan\"))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: `item` has been deprecated and will be removed in a future version\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress = 5.58659217877095%\n",
      "progress = 11.1731843575419%\n",
      "progress = 16.75977653631285%\n",
      "progress = 22.3463687150838%\n",
      "progress = 27.932960893854748%\n",
      "progress = 33.5195530726257%\n",
      "progress = 39.10614525139665%\n",
      "progress = 44.6927374301676%\n",
      "progress = 50.27932960893855%\n",
      "progress = 55.865921787709496%\n",
      "progress = 61.452513966480446%\n",
      "progress = 67.0391061452514%\n",
      "progress = 72.62569832402235%\n",
      "progress = 78.2122905027933%\n",
      "progress = 83.79888268156425%\n",
      "progress = 89.3854748603352%\n",
      "progress = 94.97206703910615%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17690, 49)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "X, y = [], []\n",
    "for i, row in train_cuts.iterrows():\n",
    "    count += 1\n",
    "    installation_id, game_session = row['installation_id'], row['game_session']\n",
    "    df = train[train['installation_id'] == installation_id]\n",
    "    # get the timestamp of the cut row\n",
    "    cut_time = df.loc[i,'timestamp']\n",
    "    # cut the df\n",
    "    df = df[df['timestamp'] <= cut_time]\n",
    "    if df.empty:\n",
    "        continue\n",
    "    df['accuracy_group'] = row['accuracy_group']\n",
    "    \n",
    "    # added player calculations, used to create features below\n",
    "    longest_wild_click_run, num_wild_click_sessions_grouped = longest_wild_click_session(df, 5, 0.9)\n",
    "    p_v_g_stats = calc_player_vs_global_features(df, global_mean_session_lengths, global_median_session_lengths)\n",
    "    p_v_g_gt_sum_mean, p_v_g_ec_sum_mean, p_v_g_gt_sum_median, p_v_g_ec_sum_median = p_v_g_stats\n",
    "    \n",
    "    feature = {'worlds_played': max(df['world'].nunique(), 0),\n",
    "               'time_as_player': max((df.iloc[-1]['timestamp'] - df.iloc[0]['timestamp']).total_seconds(), 0),\n",
    "               'num_assessments': max((df['type'] == 'Assessment').sum(), 0),\n",
    "               'avg_assessment_time': max(df[df['type'] == 'Assessment']['game_time'].mean(), 0),\n",
    "               'tot_time_playing_game': max(df['game_time'].sum(), 0),\n",
    "               'prev_assessment_accuracy': get_prev_assessment_accuracy(df),\n",
    "               'num_events_during_school_hours': num_events_during_school_hours(df),\n",
    "               'exit_type_other_than_gamecompleted': calc_exit_type_other_than_gamecompleted(df),\n",
    "               'game_play_total_time': calc_game_play_total_time(df),\n",
    "               'num_wild_click_sessions': num_wild_click_sessions(df, 5, 0.9),\n",
    "               'num_wild_click_sessions_grouped': num_wild_click_sessions_grouped,\n",
    "               'longest_wild_click_run': longest_wild_click_run,\n",
    "               'length_of_current_play_session': length_of_current_play_session(df, 30),\n",
    "               'num_play_sessions': num_play_sessions(df, 30),\n",
    "               'current_play_session_compared_to_mean': current_play_session_compared_to_mean(df, 30),\n",
    "               'current_play_session_compared_to_median': current_play_session_compared_to_median(df, 30),\n",
    "               'p_v_g_gt_sum_mean': p_v_g_gt_sum_mean,\n",
    "               'p_v_g_ec_sum_mean': p_v_g_ec_sum_mean,\n",
    "               'p_v_g_gt_sum_median': p_v_g_gt_sum_median,\n",
    "               'p_v_g_ec_sum_median': p_v_g_ec_sum_median,\n",
    "               'num_events_correct_json': num_events_correct_json(df),\n",
    "               'num_events_incorrect_json': num_events_correct_json(df),\n",
    "               'num_events_correct_eventid': num_events_correct_eventid(df, correct_events),\n",
    "               'num_events_incorrect_eventid': num_events_incorrect_eventid(df, incorrect_events),\n",
    "               'part_of_day': max(df[\"segment_of_day\"].iloc[-1], 0),\n",
    "               'assessment_taken': max(df[\"assessment\"].iloc[-1], 0),                \n",
    "               'time_playing_for': max(df[\"game_time\"].iloc[-1], 0),\n",
    "               'times_took_asses': times_took_assess(df),\n",
    "               '2010': max(df[2010].iloc[-1], 0),\n",
    "               '2020': max(df[2020].iloc[-1], 0),\n",
    "               '2025': max(df[2025].iloc[-1], 0),\n",
    "               '2030': max(df[2030].iloc[-1], 0),\n",
    "               '2035': max(df[2035].iloc[-1], 0),\n",
    "               '3010': max(df[3010].iloc[-1], 0),\n",
    "               '3020': max(df[3020].iloc[-1], 0),\n",
    "               '3021': max(df[3021].iloc[-1], 0),\n",
    "               '3110': max(df[3110].iloc[-1], 0),\n",
    "               '3120': max(df[3120].iloc[-1], 0),\n",
    "               '3121': max(df[3121].iloc[-1], 0),\n",
    "               '4020': max(df[4020].iloc[-1], 0),\n",
    "               '4025': max(df[4025].iloc[-1], 0),\n",
    "               '4030': max(df[4030].iloc[-1], 0),\n",
    "               '4035': max(df[4035].iloc[-1], 0),\n",
    "               '4040': max(df[4040].iloc[-1], 0),\n",
    "               '4070': max(df[4070].iloc[-1], 0),\n",
    "               '4080': max(df[4080].iloc[-1], 0),\n",
    "               '4090': max(df[4090].iloc[-1], 0),\n",
    "               '4100': max(df[4100].iloc[-1], 0),\n",
    "               '4110': max(df[4110].iloc[-1], 0)\n",
    "#                'total_number_of_misses': total_number_of_misses(df),\n",
    "#                'percentage_of_misses': percentage_of_misses(df),\n",
    "#                'avg_assessment_accuracy': df[df['type'] == 'Assessment']['accuracy'].mean(),\n",
    "#                'total_correct': max(df['num_correct'].sum(), 0),\n",
    "#                'total_incorrect': max(df['num_incorrect'].sum(), 0),\n",
    "#                'playtime_vs_avg': time_compared_to_normal(df),\n",
    "              }\n",
    "    \n",
    "    X.append(feature)\n",
    "    y.append(row['accuracy_group'])\n",
    "    \n",
    "    if count % 1000 == 0:\n",
    "        print('progress = {}%'.format(count/17690*100))\n",
    "    \n",
    "#     if count > 2:  # note we're just making features for the first n cuts\n",
    "#         break\n",
    "\n",
    "X = pd.DataFrame(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17690, 17690)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('all_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17690, 49)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = pd.read_csv('all_features.csv')\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment data to even out the classes\n",
    "X_y = pd.concat([X, pd.Series(y, name='labels')], axis=1)\n",
    "\n",
    "X_y['labels'] = X_y['labels'].astype('int64')\n",
    "zeros = X_y[X_y['labels'] == 0]\n",
    "ones = X_y[X_y['labels'] == 1]\n",
    "twos = X_y[X_y['labels'] == 2]\n",
    "\n",
    "X_y = pd.concat([X_y, zeros, ones, ones, ones, twos, twos, twos])\n",
    "X = X_y[[col for col in X_y.columns if col not in ['labels']]]\n",
    "y = X_y['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:6287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "# fill missing values\n",
    "fill_vals = {'assessment_taken': 0}\n",
    "X.fillna(fill_vals, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# scale features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X2 = X.copy()\n",
    "for col in X2.columns:\n",
    "    scaler = StandardScaler()\n",
    "    data = np.array(X2[col]).reshape(-1, 1)\n",
    "    scaler.fit(data)\n",
    "    X2[col] = scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/5 -- kappa_score: 1.0\n",
      "Run 2/5 -- kappa_score: 1.0\n",
      "Run 3/5 -- kappa_score: 1.0\n",
      "Run 4/5 -- kappa_score: 1.0\n",
      "Run 5/5 -- kappa_score: 1.0\n",
      "\n",
      "mean score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "model = tree.DecisionTreeClassifier\n",
    "k_folds = 5\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "total_runs = skf.get_n_splits()\n",
    "scores = []\n",
    "count = 0\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    count += 1\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    clf = model()\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    score = cohen_kappa_score(clf.predict(X_test), y_test, weights='quadratic')\n",
    "    scores.append(score)\n",
    "    print('Run {}/{} -- kappa_score: {}'.format(count, total_runs, score))\n",
    "print('\\nmean score: {}'.format(sum(scores)/len(scores))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open('model_001.pkl', 'wb') as f:\n",
    "    pkl.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
